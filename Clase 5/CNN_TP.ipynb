{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9_1a5iymIvC"
      },
      "source": [
        "## 8. EJERCICIO\n",
        "\n",
        "Vamos a armar una pequeña competición en el curso.\n",
        "El objetivo es armar una arquitectura de CNN que identifique el dataset MNIST.\n",
        "Se van a usar capas de convolución, de activación y de pooling a elección. Cada alumno eligirá su modelo y los respectivos hiperparámetros, lo entrenará y presentará los siguientes resultados:\n",
        "\n",
        "*   `test_acc` (del test final)\n",
        "*   `n_parameter`\n",
        "*   `n_layers` (conv + activacion + pooling = 1 capa)\n",
        "*   `n_epochs` de entrenamiento usadas.\n",
        "\n",
        "\n",
        "El modelo se deberá ajustar a los siguientes parámetros:\n",
        "\n",
        "*   train: 80%, validation: 10%, test: 10% (los datos serán dados así todos usan el mismo set para cada grupo. Están en el github el curso).\n",
        "*   capa final de salida será una softmax de 10 elementos.\n",
        "*   coss_function será `CrossEntropyLoss`.\n",
        "\n",
        "El ganador de la competencia será aquel que consiga el mayor `score` empleando la siguietne fórmula:\n",
        "\n",
        "$$ score = \\frac{1}{log_{10}(n\\_parameter)} * \\frac{10}{n\\_epochs}*test\\_acc*n\\_layers$$\n",
        "\n",
        "Deberan presentar su código colab funcionando y el score alcanzado (con los valores de cada variable que compone el score).\n",
        "\n",
        "Es una competencia fairplay y con fines didácticos, esta formula del ```score``` fué inventada.... no usar como referencia para definir qué modelo utilizar.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wIQ8hjDpdVi"
      },
      "source": [
        "#### Importar lo necesario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uHQUjDs12DLW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x1ca9b808650>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "# import pandas\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "torch.manual_seed(17)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeJy8fjPn4wi"
      },
      "source": [
        "#### configuramos el `device` acorde al device disponible\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "lOV9xybtn4I3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nQ-MLk6Do8e"
      },
      "source": [
        "1. Cargar base de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean: 33.32154206905977\n",
            "std: 78.57221140308602\n",
            "torch.Size([56000, 1, 28, 28])\n",
            "torch.Size([56000, 1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "x_train = pickle.load( open( \"train.pkl\", \"rb\" ) )\n",
        "y_train =  pickle.load( open( \"train_label.pkl\", \"rb\" ) )\n",
        "x_val =  pickle.load( open( \"val.pkl\", \"rb\" ) )\n",
        "y_val =  pickle.load( open( \"val_label.pkl\", \"rb\" ) )\n",
        "x_test =  pickle.load( open( \"test.pkl\", \"rb\" ) )\n",
        "y_test =  pickle.load( open( \"test_label.pkl\", \"rb\" ) )\n",
        "\n",
        "\n",
        "mean = np.mean(x_train)\n",
        "print('mean: {}'.format(mean))\n",
        "std = np.std(x_train)\n",
        "print('std: {}'.format(std))\n",
        "\n",
        "x_train = torch.from_numpy(x_train).unsqueeze(1)\n",
        "x_val = torch.from_numpy(x_val).unsqueeze(1)\n",
        "x_test = torch.from_numpy(x_test).unsqueeze(1)\n",
        "\n",
        "y_train = torch.from_numpy(y_train)\n",
        "y_val = torch.from_numpy(y_val)\n",
        "y_test = torch.from_numpy(y_test)\n",
        "\n",
        "\n",
        "transforms = torchvision.transforms.Compose([\n",
        "    # torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean,std)\n",
        "])\n",
        "\n",
        "x_train_norm = transforms(x_train.float())\n",
        "x_val_norm = transforms(x_val.float())\n",
        "x_test_norm = transforms(x_test.float())\n",
        "\n",
        "print(np.shape(x_train_norm))\n",
        "print(np.shape(x_train_norm))\n",
        "\n",
        "\n",
        "train_set = TensorDataset(x_train_norm,y_train)\n",
        "val_set = TensorDataset(x_val_norm,y_val)\n",
        "test_set = TensorDataset(x_test_norm,y_test)\n",
        "\n",
        "dataloader = {\n",
        "    'train': torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True, pin_memory=True),\n",
        "    'val': torch.utils.data.DataLoader(val_set, batch_size=64, shuffle=True, pin_memory=True),\n",
        "    'test': torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False, pin_memory=True)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oikthAE4Dteb"
      },
      "source": [
        "2. Ver que la base de datos esté OK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyq2UFIl-Qjy",
        "outputId": "ed7a0a94-d5e7-4ae4-b111-118f9805fae3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'label: 5')"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "x_train,y_train=next(iter(dataloader['train']))\n",
        "\n",
        "print(np.shape(x_train))\n",
        "print(np.shape(y_train))\n",
        "# print(np.shape(x_val))\n",
        "# print(np.shape(y_val))\n",
        "# print(np.shape(x_test))\n",
        "# print(np.shape(y_test))\n",
        "\n",
        "k=0\n",
        "plt.figure()\n",
        "plt.imshow(x_train[k].squeeze(0))\n",
        "plt.title('label: {}'.format(y_train[k]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY0TN4erDxRd"
      },
      "source": [
        "3. Construyo mi CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {},
      "outputs": [],
      "source": [
        "def block(c_in, c_out, k=3, p=1, s=1, pk=3, ps=2, pp=1):\n",
        "    return torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(c_in, c_out, k, padding=p, stride=s), # conv\n",
        "        torch.nn.ReLU(),                                      # activation\n",
        "        torch.nn.MaxPool2d(pk, stride=ps, padding=pp)         # pooling\n",
        "    )\n",
        "\n",
        "class CNN(torch.nn.Module):\n",
        "  def __init__(self, n_channels=1, n_outputs=10):\n",
        "    super().__init__()\n",
        "    self.conv1 = block(n_channels, 16)\n",
        "    self.conv1_out = None\n",
        "    self.conv2 = block(16, 32)\n",
        "    self.conv2_out = None\n",
        "    self.conv3 = block(32, 32)\n",
        "    self.conv3_out = None\n",
        "    #self.conv4 = block(128, 128)\n",
        "    #self.conv4_out = None\n",
        "    self.fc = torch.nn.Linear(1568, n_outputs) # verificar la dim de la salida para calcular el tamaño de la fully conected!!\n",
        "    self.sm = torch.nn.Softmax(dim=1)\n",
        "    print('Red creada')\n",
        "    print('arquitectura:')\n",
        "    print(self)\n",
        "    # Me fijo en el número de capas\n",
        "    i=0\n",
        "    for layer in self.children():\n",
        "        i=i+1\n",
        "    print('Número total de capas de CNN (conv+act+polling) + finales : ', i)\n",
        "    \n",
        "    # Me fijo en el número de parámetros entrenables\n",
        "    pytorch_total_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "    print('Número total de parámetros a entrenar: ', pytorch_total_params)\n",
        "\n",
        "  def validar_dim(self):\n",
        "    # es una funcion forward que imprime la dimension de cada paso\n",
        "    # la defino distinto de la forward standard para que cuando entrenemos\n",
        "    # no nos llene la pantalla de información inecesaria.\n",
        "\n",
        "    print(\"Validacion de dimensiones\")\n",
        "    tam = input(\"Ingrese tamaño de entrada: \")\n",
        "    x = torch.randn(1, 1, int(tam), int(tam))\n",
        "    print(\"Tamaño entrada: \", x.shape)\n",
        "    x = self.conv1(x)\n",
        "    print(\"Tamaño salida conv1: \", x.shape)\n",
        "    x = self.conv2(x)\n",
        "    print(\"Tamaño salida conv2: \", x.shape)\n",
        "\n",
        "    # x = self.conv3(x)\n",
        "    # print(\"Tamaño salida conv3: \", x.shape)\n",
        "\n",
        "    # x = self.conv4(x)\n",
        "    # print(\"Tamaño salida conv4: \", x.shape)\n",
        "\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    print(\"Tamaño imagen vectorizada: \", x.shape)\n",
        "    x = self.fc(x)\n",
        "    print(\"Tamaño salida fc (nro clases): \", x.shape)\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.conv1_out = self.conv1(x)\n",
        "    self.conv2_out = self.conv2(self.conv1_out)\n",
        "    self.conv3_out = self.conv3(self.conv2_out)\n",
        "    # self.conv4_out = self.conv4(self.conv3_out)\n",
        "    y = self.conv2_out.view(self.conv2_out.shape[0], -1)\n",
        "    y = self.fc(y)\n",
        "    # x = self.sm(x)\n",
        "    return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGWzAaLqwiHZ"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Red creada\n",
            "arquitectura:\n",
            "CNN(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=1568, out_features=10, bias=True)\n",
            "  (sm): Softmax(dim=1)\n",
            ")\n",
            "Número total de capas de CNN (conv+act+polling) + finales :  5\n",
            "Número total de parámetros a entrenar:  29738\n",
            "Validacion de dimensiones\n",
            "Tamaño entrada:  torch.Size([1, 1, 28, 28])\n",
            "Tamaño salida conv1:  torch.Size([1, 16, 14, 14])\n",
            "Tamaño salida conv2:  torch.Size([1, 32, 7, 7])\n",
            "Tamaño imagen vectorizada:  torch.Size([1, 1568])\n",
            "Tamaño salida fc (nro clases):  torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "model = CNN()\n",
        "model.validar_dim()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQjMdMNKwj2H"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm # <- para graficar la barra de avance\n",
        "\n",
        "\n",
        "def fit(model, dataloader, epochs=5):\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        train_loss, train_acc = [], []\n",
        "        bar = tqdm(dataloader['train'])\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(X)\n",
        "            loss = criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            ####\n",
        "            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "            train_acc.append(acc)\n",
        "            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n",
        "        bar = tqdm(dataloader['test'])\n",
        "        val_loss, val_acc = [], []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in bar:\n",
        "                X, y = batch\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                y_hat = model(X)\n",
        "                loss = criterion(y_hat, y)\n",
        "                val_loss.append(loss.item())\n",
        "                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "                val_acc.append(acc)\n",
        "                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n",
        "        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f} acc {np.mean(train_acc):.5f} val_acc {np.mean(val_acc):.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aQ5n86Kwk7B"
      },
      "source": [
        "# score final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss 0.15438 acc 0.95511: 100%|██████████| 875/875 [00:06<00:00, 144.96it/s]\n",
            "val_loss 0.11011 val_acc 0.96690: 100%|██████████| 110/110 [00:00<00:00, 275.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1 loss 0.15438 val_loss 0.11011 acc 0.95511 val_acc 0.96690\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 1\n",
        "i=0\n",
        "for layer in model.children():\n",
        "    i=i+1\n",
        "n_layers = i\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "fit(model, dataloader, epochs= n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_test,y_test=next(iter(dataloader['test']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "$$ score = \\frac{1}{log_{10}(n\\_parameter)} * \\frac{10}{n\\_epochs}*test\\_acc*n\\_layers$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.953125\n",
            "10.653460475710911\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "y_hat = model(x_test.cuda())\n",
        "test_acc = (y_test.cuda() == torch.argmax(y_hat, axis=1)).sum().item() / len(y_test.cuda())\n",
        "print(test_acc)\n",
        "score = 10*test_acc *n_layers /(np.log10(n_parameters) * n_epochs )\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CNN_TP.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "d0ad2a5384a224f6ff41af024fc0657a32ddd13252b3e5cbedbed3e35137bcfc"
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
